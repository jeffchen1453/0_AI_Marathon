{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請自行定義一個 loss function, 為 0.3 * focal loss + 0.7 cross-entropy，訓練並比較結果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "from keras.utils import np_utils\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = np_utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.14 GiB for an array with shape (50000, 32, 32, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22376/2281964246.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Preproc the inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreproc_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreproc_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22376/1214487259.py\u001b[0m in \u001b[0;36mpreproc_x\u001b[1;34m(x, flatten)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreproc_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.14 GiB for an array with shape (50000, 32, 32, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.14 GiB for an array with shape (50000, 32, 32, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22376/3706264597.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Preproc the inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreproc_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreproc_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22376/1214487259.py\u001b[0m in \u001b[0;36mpreproc_x\u001b[1;34m(x, flatten)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreproc_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.14 GiB for an array with shape (50000, 32, 32, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "import numpy as np\n",
    "mask = np.zeros((50000, 32, 32, 3),dtype='uint8')\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路，並加入 BN layer\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 1024\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.3132617>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = float(1)\n",
    "import tensorflow as tf \n",
    "y_pred = float(1)\n",
    "sigmoids_weighted = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "tf.reduce_mean(sigmoids_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "\"\"\"Code Here\n",
    "撰寫一個 loss function, 使其可以結合 focal loss 與 crossentropy loss\n",
    "\"\"\"\n",
    "\n",
    "def combined_loss(gamma=2., alpha=4.,ce_weights_list=0):\n",
    "    \n",
    "    \"\"\"Define the customized loss.\"\"\"\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"Focal loss for multi-classification\n",
    "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
    "        \"\"\"\n",
    "        epsilon = 1e-8\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "\n",
    "        model_out = tf.add(y_pred, epsilon)\n",
    "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
    "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
    "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
    "#         combined_loss = (1-ce_weights_list)*f1 + ce_weights_list*ce\n",
    "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
    "        reduced_ce = tf.reduce_max(ce, axis=1)\n",
    "        return tf.reduce_mean((1-ce_weights_list) * reduced_fl + ce_weights_list * reduced_ce)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "ce_weights_list = [0., 0.3, 0.5, 0.7, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of exp: 0, ce_weight: 0.00\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 32, 32, 512)       2048      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 32, 32, 256)       131328    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 32, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 32, 32, 128)       32896     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " output (Dense)              (None, 32, 32, 10)        1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171,146\n",
      "Trainable params: 169,354\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\1_220107_Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\1_220107_Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\陳長昌\\AppData\\Local\\Temp/ipykernel_22376/3183364034.py\", line 18, in focal_loss_fixed  *\n        y_true = tf.convert_to_tensor(y_true, tf.float32)\n\n    ValueError: Tensor conversion requested dtype float32 for Tensor with dtype uint8: <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=uint8>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22376/4134161304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcombined_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     model.fit(x_train, y_train, \n\u001b[0m\u001b[0;32m     16\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\1_220107_Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\1_220107_Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\1_220107_Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\陳長昌\\AppData\\Local\\Temp/ipykernel_22376/3183364034.py\", line 18, in focal_loss_fixed  *\n        y_true = tf.convert_to_tensor(y_true, tf.float32)\n\n    ValueError: Tensor conversion requested dtype float32 for Tensor with dtype uint8: <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=uint8>\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "results = {}\n",
    "\n",
    "for i, ce_w in enumerate(ce_weights_list):\n",
    "    print(\"Numbers of exp: %i, ce_weight: %.2f\" % (i, ce_w))\n",
    "\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    optimizer = tf.keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    \"\"\"Code Here\n",
    "    將自定義的 loss function 加入模型\n",
    "    \"\"\"\n",
    "    model.compile(loss=combined_loss(), metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True\n",
    "             )\n",
    "    \n",
    "    # Collect results\n",
    "    exp_name_tag = (\"exp-%s-ceweights-%f\" % (i, ce_w))\n",
    "    results[exp_name_tag] = {'train-loss': model.history.history[\"loss\"],\n",
    "                             'valid-loss': model.history.history[\"val_loss\"],\n",
    "                             'train-acc': model.history.history[\"accuracy\"],\n",
    "                             'valid-acc': model.history.history[\"val_accuracy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "NUM_COLORS = len(results.keys())\n",
    "\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "color_bar = [scalarMap.to_rgba(i) for i in range(NUM_COLORS)]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
