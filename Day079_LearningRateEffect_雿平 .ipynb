{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請比較 SGD optimizer 不同的 momentum 及使用 nesterov 與否的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若想使用可自行開啟)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "from keras.utils import np_utils\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = np_utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.100000\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " hidden_layer3 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\1_220107_Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "196/196 [==============================] - 7s 32ms/step - loss: 2.1706 - accuracy: 0.1682 - val_loss: 2.0446 - val_accuracy: 0.1971\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 1.9856 - accuracy: 0.2333 - val_loss: 1.9316 - val_accuracy: 0.2566\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 1.8977 - accuracy: 0.2801 - val_loss: 1.9040 - val_accuracy: 0.2852\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.8705 - accuracy: 0.2953 - val_loss: 1.8632 - val_accuracy: 0.3071\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 6s 28ms/step - loss: 1.8204 - accuracy: 0.3262 - val_loss: 1.8850 - val_accuracy: 0.3091\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.8123 - accuracy: 0.3299 - val_loss: 1.7951 - val_accuracy: 0.3413\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.7942 - accuracy: 0.3408 - val_loss: 1.8001 - val_accuracy: 0.3355\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.7833 - accuracy: 0.3458 - val_loss: 1.7863 - val_accuracy: 0.3437\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.7858 - accuracy: 0.3470 - val_loss: 1.8521 - val_accuracy: 0.3266\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.7583 - accuracy: 0.3594 - val_loss: 1.9182 - val_accuracy: 0.3149\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.7196 - accuracy: 0.3783 - val_loss: 1.8143 - val_accuracy: 0.3483\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.6932 - accuracy: 0.3914 - val_loss: 1.7395 - val_accuracy: 0.3801\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.6870 - accuracy: 0.3912 - val_loss: 1.6992 - val_accuracy: 0.3838\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.6805 - accuracy: 0.3968 - val_loss: 1.7599 - val_accuracy: 0.3617\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.6815 - accuracy: 0.3983 - val_loss: 1.7627 - val_accuracy: 0.3736\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.6726 - accuracy: 0.4012 - val_loss: 1.7668 - val_accuracy: 0.3737\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.6644 - accuracy: 0.4027 - val_loss: 1.7885 - val_accuracy: 0.3606\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 6s 29ms/step - loss: 1.6608 - accuracy: 0.4058 - val_loss: 1.6976 - val_accuracy: 0.3804\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 6s 28ms/step - loss: 1.6461 - accuracy: 0.4082 - val_loss: 1.7089 - val_accuracy: 0.3916\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 6s 28ms/step - loss: 1.6434 - accuracy: 0.4105 - val_loss: 1.7340 - val_accuracy: 0.3890\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 1.6433 - accuracy: 0.4142 - val_loss: 1.7595 - val_accuracy: 0.3720\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 6s 28ms/step - loss: 1.6362 - accuracy: 0.4151 - val_loss: 1.7461 - val_accuracy: 0.3779\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 1.6389 - accuracy: 0.4165 - val_loss: 1.7376 - val_accuracy: 0.3808\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 6s 28ms/step - loss: 1.6318 - accuracy: 0.4161 - val_loss: 1.8066 - val_accuracy: 0.3611\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 1.6343 - accuracy: 0.4181 - val_loss: 1.7071 - val_accuracy: 0.3892\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 6s 29ms/step - loss: 1.6335 - accuracy: 0.4182 - val_loss: 1.7744 - val_accuracy: 0.3758\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 6s 30ms/step - loss: 1.6418 - accuracy: 0.4134 - val_loss: 1.8415 - val_accuracy: 0.3582\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 7s 33ms/step - loss: 1.6308 - accuracy: 0.4206 - val_loss: 1.7413 - val_accuracy: 0.3855\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 6s 33ms/step - loss: 1.6210 - accuracy: 0.4244 - val_loss: 1.7212 - val_accuracy: 0.3940\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 5s 28ms/step - loss: 1.6048 - accuracy: 0.4316 - val_loss: 1.6982 - val_accuracy: 0.4056\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.6041 - accuracy: 0.4296 - val_loss: 1.7077 - val_accuracy: 0.3877\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.6056 - accuracy: 0.4311 - val_loss: 1.8225 - val_accuracy: 0.3671\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.6058 - accuracy: 0.4320 - val_loss: 1.7319 - val_accuracy: 0.3842\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.5948 - accuracy: 0.4347 - val_loss: 1.7578 - val_accuracy: 0.3713\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.5885 - accuracy: 0.4389 - val_loss: 1.7664 - val_accuracy: 0.3919\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 6s 28ms/step - loss: 1.5890 - accuracy: 0.4372 - val_loss: 1.7558 - val_accuracy: 0.3866\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.5867 - accuracy: 0.4384 - val_loss: 1.6448 - val_accuracy: 0.4120\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.5828 - accuracy: 0.4389 - val_loss: 1.6748 - val_accuracy: 0.4094\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.5843 - accuracy: 0.4395 - val_loss: 1.7695 - val_accuracy: 0.3792\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.5901 - accuracy: 0.4365 - val_loss: 1.6476 - val_accuracy: 0.4178\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.5631 - accuracy: 0.4459 - val_loss: 1.6651 - val_accuracy: 0.4124\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 1.5608 - accuracy: 0.4464 - val_loss: 1.6612 - val_accuracy: 0.4164\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 1.5606 - accuracy: 0.4485 - val_loss: 1.7639 - val_accuracy: 0.3881\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5604 - accuracy: 0.4455 - val_loss: 1.6949 - val_accuracy: 0.4076\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 1.5582 - accuracy: 0.4507 - val_loss: 1.6778 - val_accuracy: 0.4106\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 1.5560 - accuracy: 0.4473 - val_loss: 1.6698 - val_accuracy: 0.4131\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 6s 32ms/step - loss: 1.5571 - accuracy: 0.4492 - val_loss: 1.7081 - val_accuracy: 0.3933\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 6s 31ms/step - loss: 1.5414 - accuracy: 0.4530 - val_loss: 1.6948 - val_accuracy: 0.4049\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 5s 27ms/step - loss: 1.5514 - accuracy: 0.4483 - val_loss: 1.6635 - val_accuracy: 0.4174\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 6s 28ms/step - loss: 1.5454 - accuracy: 0.4517 - val_loss: 1.7228 - val_accuracy: 0.3879\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_43180/2508069956.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"\n",
    "使用迴圈，建立不同 Learning rate 的模型並訓練\n",
    "\"\"\"\n",
    "import tensorflow as tf \n",
    "for lr in LEARNING_RATE:\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with LR = %.6f\" % (lr))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    optimizer = tf.keras.optimizers.SGD(lr=lr, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-lr-%s\" % str(lr)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
