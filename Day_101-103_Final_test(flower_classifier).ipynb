{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day101-103_Final_test(flower_classifier).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunyuan0221/3rd-ML100days/blob/master/Day101_103_Final_test(flower_classifier).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LinzcstyI4lr",
        "colab_type": "text"
      },
      "source": [
        "# Flowers classifier專案流程\n",
        "***\n",
        "### 1.載入資料並轉換Array(Load image data and transform to array)\n",
        "\n",
        "### 2.儲存資料(Save array data)\n",
        "\n",
        "### 3.載入陣列資料(Load array data)\n",
        "\n",
        "### 4.資料前處理(Data perprocess)\n",
        "\n",
        "### 5.訓練資料分割(Training Data split to train and test)\n",
        "\n",
        "### 6.模型建立(Create Model)\n",
        "\n",
        "### 7.優化模型準確率方法\n",
        "\n",
        "### 8.進行模型擬合\n",
        "\n",
        "### 9.載入最佳模型或weights\n",
        "\n",
        "### 10.進行預測資料的預測"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f6jgS9VPzDV",
        "colab_type": "text"
      },
      "source": [
        "### 1.載入資料\n",
        "***\n",
        "- 我們可以透過code，將資料從Google Drive載入。\n",
        "  - from google.colab import drive\n",
        "  - google drive 的基礎路徑 : '/content/drive/' ，執行時會需要登入驗證\n",
        "  - 進入後，我們可以再輸入我們資料放置的路徑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk3oCA6xHmzj",
        "colab_type": "code",
        "outputId": "86e129f4-c681-4cdd-a181-5365846d97c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "path = drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTBuKh_-YZMt",
        "colab_type": "text"
      },
      "source": [
        "- 透過ls或os.listdir()就可以看目前路徑下，因此我們可以看到已經轉到Drive的根目錄(root_path)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtzbjLj6YTml",
        "colab_type": "code",
        "outputId": "ab87c0de-889b-4ba5-dc5f-373a69f6f99d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcwDXH-uZJzO",
        "colab_type": "text"
      },
      "source": [
        "### 1.載入資料\n",
        "***\n",
        "- 載入圖片&轉換資料型態：處理好資料路徑後，我們可以正式將training data和testing data載入，由於我們要載入的是圖片，因此可以用keras內建代碼或另外使用cv2\n",
        "  - from keras.preprocessing.image import img_to_array, load\n",
        "  \n",
        "- 加入進度表：由於載入圖片並轉換為array型態很花時間，因此加入進度表觀察狀況"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo_9xepBOpWG",
        "colab_type": "code",
        "outputId": "7bcb03a7-60bc-4e3c-e734-c26ea75cba6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "# save array data\n",
        "from numpy import save\n",
        "\n",
        "# load image and tranform to array type\n",
        "import keras\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# for進度表\n",
        "from tqdm import trange\n",
        "from time import sleep\n",
        "\n",
        "# for image visiulization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Al_EpNhcQld",
        "colab_type": "text"
      },
      "source": [
        "### 1.載入資料\n",
        "***\n",
        "- def load_xtrain_ytrian_img( )：第一次載入training圖片使用，同時進行以下動作:\n",
        "  1. image to array：圖片轉陣列\n",
        "  2. label：以數字標記每種花類別\n",
        "- def load_predict_img( )：第一次載入預測圖片使用，同時進行以下動作：\n",
        "  1. image to array：圖片轉陣列\n",
        "  2. 因為是預測所以不用標記花類別"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlZxZ3sTOy7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_xtrain_ytrian_img(path = 'drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/image_data/train', img_size=(150, 150)):\n",
        "    Xtrain = list()\n",
        "    labels = list()\n",
        "    #path = 'drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/image_data/train'\n",
        "    for rootname, dirname, filenames in os.walk(path):\n",
        "        # 當filenames>0 表示我們在的資料夾是有檔案的\n",
        "        if len(filenames) > 0:\n",
        "            # 設立進度表觀察轉換進度            \n",
        "            for i in trange(len(filenames)):\n",
        "                img = load_img(rootname + '/' + filenames[i], target_size=img_size)\n",
        "                img_arr = img_to_array(img)\n",
        "                #img_arr = img_arr.astype(\"uint8\")\n",
        "                Xtrain.append(img_arr)\n",
        "            \n",
        "                # 紀錄training set的label值\n",
        "                if rootname.endswith('daisy') == True:\n",
        "                    label = 0\n",
        "                    labels.append(label)\n",
        "                elif rootname.endswith('dandelion') == True:\n",
        "                    label = 1\n",
        "                    labels.append(label)\n",
        "                elif rootname.endswith('rose') == True:\n",
        "                    label = 2\n",
        "                    labels.append(label)\n",
        "                elif rootname.endswith('sunflower') == True:\n",
        "                    label = 3\n",
        "                    labels.append(label)\n",
        "                else:\n",
        "                    label = 4\n",
        "                    labels.append(label)\n",
        "\n",
        "    xtrain = np.asarray(Xtrain)\n",
        "    ytrain = np.asarray(labels)\n",
        "    print(f'Train x shape:{xtrain.shape}\\nTrain y shape:{ytrain.shape}')\n",
        "    return xtrain, ytrain\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QZFchGKPIKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_predictX_img(path = 'drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/image_data/test/', img_size=(150, 150)):\n",
        "    predictX = list()\n",
        "    #path = '/kaggle/input/ml100-03-final/image_data/test/'\n",
        "    #path = 'drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/image_data/test/'\n",
        "    files_name = os.listdir(path)\n",
        "    for i in trange(len(files_name)):\n",
        "        img = load_img(path + files_name[i], target_size=img_size)\n",
        "        img_arr = img_to_array(img)\n",
        "        #img_arr = img_arr.astype(\"uint8\")\n",
        "        predictX.append(img_arr)\n",
        "\n",
        "    predictX = np.asarray(predictX)\n",
        "    print(f'Predict X shape:{predictX.shape}')\n",
        "    return predictX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCl6bjn-DDgy",
        "colab_type": "text"
      },
      "source": [
        "### 2.儲存資料\n",
        "***\n",
        "- 將轉換後的陣列資料進行儲存，這樣我們就不用每次載入都要重新轉換資料。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuGCX9vdPU8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_data(xtrain, ytrain, predictX, img_size=(150, 150)):\n",
        "    # 將轉換後的資料另存起來\n",
        "    save('drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/xtrain_input_shape_%s.npy' %str(img_size[0]), xtrain)\n",
        "    print('xtrain save finish!')\n",
        "    save('drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/ytrain_input_shape_%s.npy' %str(img_size[0]), ytrain)\n",
        "    print('ytrain save finish!')\n",
        "    save('drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/predictX_input_shape_%s.npy' %str(img_size[0]), predictX)\n",
        "    print('predictX save finish!')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LK3FWRDFXVM",
        "colab_type": "text"
      },
      "source": [
        "### 3.載入陣列資料\n",
        "***\n",
        "- 將儲存的陣列資料載入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvBDBCzwHzaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_arr(root_path = 'drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/', \n",
        "                  xtrain_path = 'xtrain_input_shape_150.npy', \n",
        "                  ytrain_path = 'ytrain_input_shape_150.npy', \n",
        "                  predictX_path = 'predictX_input_shape_150.npy'):\n",
        "  \n",
        "    #root_path = 'drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/'\n",
        "    xtrain = np.load(root_path + xtrain_path)\n",
        "    ytrain = np.load(root_path + ytrain_path)\n",
        "    predictX = np.load(root_path + predictX_path)\n",
        "    print(f'xtrain.shape = {xtrain.shape}, Already load in!')\n",
        "    print(f'ytrain.shape = {ytrain.shape}, Already load in!')\n",
        "    print(f'predictX.shape = {predictX.shape}, Already load in!')\n",
        "    return xtrain, ytrain, predictX\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfz50F6sPz_G",
        "colab_type": "text"
      },
      "source": [
        "- 第一次執行code使用，儲存以後就不用在執行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTQCfpjqMvgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a01cf761-f4c5-4dac-deb5-02a52f454c10"
      },
      "source": [
        "# 載入train img_data，因為後續使用的pretrain model設定input shape=(150, 150)，這邊轉換的img_size要設定相同\n",
        "xtrain, ytrain = load_xtrain_ytrian_img(img_size=(150, 150))\n",
        "\n",
        "# 載入test img_data\n",
        "xpredict = load_predictX_img(img_size=(150, 150))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [04:31<00:00,  2.50it/s]\n",
            "100%|██████████| 687/687 [04:59<00:00,  2.61it/s]\n",
            "100%|██████████| 488/488 [03:22<00:00,  2.83it/s]\n",
            "100%|██████████| 500/500 [03:29<00:00,  3.05it/s]\n",
            "100%|██████████| 515/515 [03:53<00:00,  2.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train x shape:(2823, 150, 150, 3)\n",
            "Train y shape:(2823,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [14:07<00:00,  2.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predict X shape:(2000, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8IFQvalOsa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "396b5598-8847-4bee-c830-d261b1494448"
      },
      "source": [
        "# 儲存轉換成array的資料\n",
        "save_data(xtrain=xtrain, ytrain=ytrain, predictX=xpredict)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xtrain save finish!\n",
            "ytrain save finish!\n",
            "predictX save finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGf9hphXQAI3",
        "colab_type": "text"
      },
      "source": [
        "- 經過轉換儲存後，以後直接執行此行就能載入資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG8llGXaPJNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "19fb23dd-d54b-449e-a7ad-504a22c0404b"
      },
      "source": [
        "# 載入array data\n",
        "xtrain, ytrain, xpredict = load_data_arr()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xtrain.shape = (2823, 150, 150, 3), Already load in!\n",
            "ytrain.shape = (2823,), Already load in!\n",
            "predictX.shape = (2000, 150, 150, 3), Already load in!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ7jkgMhJauD",
        "colab_type": "text"
      },
      "source": [
        "### 4.資料預處理(Data preprocess)\n",
        "***\n",
        "- x部分進行標準化：uint8，0-255將數值進行標準化到0-1在訓練上的速度會加快，因此dtype會有所改變。\n",
        "  - 原始載入的dtype=uint8(0-255)，RGB都255為白色，RGB都0為黑色\n",
        "  - 將dtype轉成float32(數值一樣是0-255)，但已經是浮點數，在float32中，RBG都1為白，RGB都0為黑。因此需要將值除以255才會是原來的色調。\n",
        "\n",
        "- y(label)部分做onehotencoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg-YNuDVUkot",
        "colab_type": "code",
        "outputId": "4e958d87-41cb-483f-a3aa-299261bd11bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "'''\n",
        "import numpy as np\n",
        "a = np.array([[[0, 0, 0], [255, 255, 255], [0, 0, 0]], \n",
        "              [[255,255,255], [0, 0, 0], [255,255,255]]], dtype='uint8')\n",
        "b = a / 255.0\n",
        "b.dtype\n",
        "c = a.astype('float32') / 255.0\n",
        "c\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0.],\n",
              "        [1., 1., 1.],\n",
              "        [0., 0., 0.]],\n",
              "\n",
              "       [[1., 1., 1.],\n",
              "        [0., 0., 0.],\n",
              "        [1., 1., 1.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVMX3lSPVeRu",
        "colab_type": "code",
        "outputId": "3a6f3f40-dd45-4ac6-a6ae-1fd03ae74a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "'''\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(a)\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGmcQSFLjDAJJapxBIEmNMwgkqXH/H26BOorOydi3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU9eGqFaJ8JK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfiqSOQEIGL9",
        "colab_type": "code",
        "outputId": "dc79c65d-3f4e-41cd-a564-fed0239266ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# 預處理\n",
        "xtrain = xtrain.astype(np.float32) / 255\n",
        "xpredict = xpredict.astype(np.float32) / 255\n",
        "print(xtrain.shape)\n",
        "print(xpredict.shape)\n",
        "\n",
        "# OHE\n",
        "ytrain = utils.to_categorical(ytrain)\n",
        "print(ytrain.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2823, 150, 150, 3)\n",
            "(2000, 150, 150, 3)\n",
            "(2823, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfOMcusMd8Lc",
        "colab_type": "text"
      },
      "source": [
        "### 5.訓練資料分割(Training Data split to train and test)\n",
        "***\n",
        "- 將訓練資料切分為訓練和驗證：\n",
        "  1. 訓練資料：用來訓練模型\n",
        "  2. 驗證資料：用來驗證訓練好的模型結果如何"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAoYEDZWJVl8",
        "colab_type": "code",
        "outputId": "f056bde9-f0d0-47bc-a6ce-8d891626d9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(xtrain, ytrain, test_size=0.25, random_state=42)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2117, 150, 150, 3)\n",
            "(706, 150, 150, 3)\n",
            "(2117, 5)\n",
            "(706, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W35lZI_kfMN2",
        "colab_type": "text"
      },
      "source": [
        "### 6.建立模型\n",
        "***\n",
        "- 使用自己建立模型\n",
        "- 使用預訓模型(Pre-train model)：VGG16、ResNet50...\n",
        "  - 這邊使用預訓模型VGG16進行預測\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLjd7LdfL-Ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Flatten, BatchNormalization\n",
        "from keras.layers import MaxPooling2D, Conv2D\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJs9Th71ihXC",
        "colab_type": "text"
      },
      "source": [
        "### 6.建立模型\n",
        "***\n",
        "- include_top=False：取消Flatten()開始的後面幾層，因為我們要預測的類別只有5種，因此我們關掉後面幾層，自己定義後面那幾層的種類。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "689117d3-9dd2-45a6-dd6a-9755a5a9a7fd",
        "id": "VpuoQ9iiigXf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "base_model=VGG16(include_top=False, weights='imagenet',input_shape=(150,150,3), pooling='avg')\n",
        "base_model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 3s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mejX8D4lzLR",
        "colab_type": "text"
      },
      "source": [
        "### 6.建立模型\n",
        "***\n",
        "- 加入我們關閉的那幾層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-hHdKotLcRh",
        "colab_type": "code",
        "outputId": "4cb1f29c-2aa8-45f4-b39a-3a322b5a131e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 14,848,325\n",
            "Trainable params: 14,847,813\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpJf53pfmhcG",
        "colab_type": "text"
      },
      "source": [
        "### 7.利用callbacks，優化模型準確率方法\n",
        "***\n",
        "- 增加訓練數據：由於訓練數據本身就少，又經過我們分成訓練集和驗證集，因此透過ImageDataGenerator就可以增加我們的數據\n",
        "- 使用動態學習率：隨著epochs的增加，更改學習率(learning rate)\n",
        "- 自動降低學習率：設定val_acc在進行幾次epoch沒有上升時，降低學習率(lr)\n",
        "- 自動儲存最佳模型：保留最佳模型或weights檔(.h5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnLcnmfBMf1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9pHzRDIL0On",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB6Jf2NTNd2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 學習率動態調整。當跑到第幾個 epcoh 時，根據設定修改學習率。這邊的數值都是參考原 paper\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-4\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 100:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 60:\n",
        "        lr *= 1e-1\n",
        "    elif epoch > 30:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSZAw-EONhIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 使用動態調整學習率\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# 使用自動降低學習率 (當 validation loss 連續 5 次沒有下降時，自動降低學習率)\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_acc', \n",
        "                               factor=0.1,\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "# 紀錄最佳model\n",
        "root_path = 'drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/'\n",
        "save_best = ModelCheckpoint(filepath=root_path + 'best_adam.h5',\n",
        "                            monitor='val_loss',\n",
        "                            save_weights_only=True,\n",
        "                            save_best_only=True)\n",
        "#checkpoint = [save_best]\n",
        "\n",
        "# 設定 callbacks\n",
        "callbacks = [lr_reducer, save_best, lr_scheduler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDx_sEnzNmEm",
        "colab_type": "code",
        "outputId": "4192c8d2-54fd-40d4-f524-b700cc1cfd6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "batch_size=128\n",
        "epochs=50\n",
        "\n",
        "\n",
        "#opt = keras.optimizers.SGD(lr=1e-2, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 14,848,325\n",
            "Trainable params: 14,847,813\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJlnUfnzpIvR",
        "colab_type": "text"
      },
      "source": [
        "### 8.進行模型擬合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4vUbsG0NrmH",
        "colab_type": "code",
        "outputId": "ab0a2988-1ff5-449c-90f9-27d3a031a31b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, \n",
        "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                              verbose = 1, \n",
        "                              validation_data = (x_test, y_test),\n",
        "                              callbacks=callbacks)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.9137 - acc: 0.6504 - val_loss: 0.9481 - val_acc: 0.6827\n",
            "Epoch 2/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 13s 791ms/step - loss: 0.5121 - acc: 0.8143 - val_loss: 0.5762 - val_acc: 0.7918\n",
            "Epoch 3/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 770ms/step - loss: 0.3850 - acc: 0.8678 - val_loss: 0.4408 - val_acc: 0.8300\n",
            "Epoch 4/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 773ms/step - loss: 0.3164 - acc: 0.8847 - val_loss: 0.4344 - val_acc: 0.8499\n",
            "Epoch 5/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 13s 792ms/step - loss: 0.2528 - acc: 0.9160 - val_loss: 0.7322 - val_acc: 0.7691\n",
            "Epoch 6/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 762ms/step - loss: 0.2327 - acc: 0.9213 - val_loss: 0.5033 - val_acc: 0.8244\n",
            "Epoch 7/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 13s 785ms/step - loss: 0.1555 - acc: 0.9536 - val_loss: 0.4102 - val_acc: 0.8654\n",
            "Epoch 8/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.1548 - acc: 0.9482 - val_loss: 0.4065 - val_acc: 0.8782\n",
            "Epoch 9/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 13s 791ms/step - loss: 0.1159 - acc: 0.9590 - val_loss: 0.4310 - val_acc: 0.8598\n",
            "Epoch 10/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 0.1298 - acc: 0.9594 - val_loss: 0.6521 - val_acc: 0.8286\n",
            "Epoch 11/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.1393 - acc: 0.9539 - val_loss: 0.6197 - val_acc: 0.8003\n",
            "Epoch 12/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 749ms/step - loss: 0.1173 - acc: 0.9617 - val_loss: 0.5255 - val_acc: 0.8626\n",
            "Epoch 13/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.1086 - acc: 0.9617 - val_loss: 0.5894 - val_acc: 0.8555\n",
            "Epoch 14/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 749ms/step - loss: 0.0586 - acc: 0.9830 - val_loss: 0.4400 - val_acc: 0.8725\n",
            "Epoch 15/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 0.0409 - acc: 0.9908 - val_loss: 0.6135 - val_acc: 0.8654\n",
            "Epoch 16/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 767ms/step - loss: 0.0428 - acc: 0.9854 - val_loss: 0.5867 - val_acc: 0.8640\n",
            "Epoch 17/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 747ms/step - loss: 0.0421 - acc: 0.9844 - val_loss: 0.4641 - val_acc: 0.8768\n",
            "Epoch 18/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 768ms/step - loss: 0.0362 - acc: 0.9889 - val_loss: 0.6128 - val_acc: 0.8541\n",
            "Epoch 19/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 751ms/step - loss: 0.0364 - acc: 0.9903 - val_loss: 0.6070 - val_acc: 0.8470\n",
            "Epoch 20/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 764ms/step - loss: 0.0448 - acc: 0.9830 - val_loss: 0.6438 - val_acc: 0.8499\n",
            "Epoch 21/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 776ms/step - loss: 0.0283 - acc: 0.9912 - val_loss: 0.6009 - val_acc: 0.8484\n",
            "Epoch 22/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 761ms/step - loss: 0.0350 - acc: 0.9884 - val_loss: 0.6078 - val_acc: 0.8470\n",
            "Epoch 23/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.0313 - acc: 0.9918 - val_loss: 0.4625 - val_acc: 0.8768\n",
            "Epoch 24/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 736ms/step - loss: 0.0279 - acc: 0.9894 - val_loss: 0.5597 - val_acc: 0.8513\n",
            "Epoch 25/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.0352 - acc: 0.9897 - val_loss: 0.9379 - val_acc: 0.8144\n",
            "Epoch 26/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 773ms/step - loss: 0.0418 - acc: 0.9883 - val_loss: 0.6394 - val_acc: 0.8428\n",
            "Epoch 27/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 730ms/step - loss: 0.0367 - acc: 0.9902 - val_loss: 0.5946 - val_acc: 0.8513\n",
            "Epoch 28/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 773ms/step - loss: 0.0267 - acc: 0.9922 - val_loss: 0.3917 - val_acc: 0.8938\n",
            "Epoch 29/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.0213 - acc: 0.9946 - val_loss: 0.8633 - val_acc: 0.8456\n",
            "Epoch 30/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 748ms/step - loss: 0.0244 - acc: 0.9936 - val_loss: 0.5932 - val_acc: 0.8683\n",
            "Epoch 31/50\n",
            "Learning rate:  0.0001\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.0166 - acc: 0.9966 - val_loss: 0.8044 - val_acc: 0.8385\n",
            "Epoch 32/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0141 - acc: 0.9952 - val_loss: 0.4707 - val_acc: 0.8739\n",
            "Epoch 33/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 747ms/step - loss: 0.0090 - acc: 0.9990 - val_loss: 0.4463 - val_acc: 0.8867\n",
            "Epoch 34/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 737ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4264 - val_acc: 0.8909\n",
            "Epoch 35/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 744ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4362 - val_acc: 0.8881\n",
            "Epoch 36/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.4488 - val_acc: 0.8867\n",
            "Epoch 37/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 728ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4461 - val_acc: 0.8881\n",
            "Epoch 38/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 749ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.4562 - val_acc: 0.8895\n",
            "Epoch 39/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.4579 - val_acc: 0.8839\n",
            "Epoch 40/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 728ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4523 - val_acc: 0.8867\n",
            "Epoch 41/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 725ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.4437 - val_acc: 0.8909\n",
            "Epoch 42/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 735ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.4385 - val_acc: 0.8938\n",
            "Epoch 43/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4436 - val_acc: 0.8895\n",
            "Epoch 44/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4437 - val_acc: 0.8895\n",
            "Epoch 45/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 741ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.4425 - val_acc: 0.8924\n",
            "Epoch 46/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 739ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.4346 - val_acc: 0.8952\n",
            "Epoch 47/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 728ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.4377 - val_acc: 0.8909\n",
            "Epoch 48/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 725ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4406 - val_acc: 0.8909\n",
            "Epoch 49/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 737ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.4419 - val_acc: 0.8895\n",
            "Epoch 50/50\n",
            "Learning rate:  1e-05\n",
            "16/16 [==============================] - 12s 731ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.4347 - val_acc: 0.8895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cimZMsNRc4k",
        "colab_type": "code",
        "outputId": "8beb0a55-73cc-4524-952e-80237cd651c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "706/706 [==============================] - 1s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4346932905591581, 0.8895184135977338]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHOJ_5MEpbeE",
        "colab_type": "text"
      },
      "source": [
        "### 9.載入最佳模型或weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1d3rs60IEDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2se66EJZIyMT",
        "colab_type": "code",
        "outputId": "aac0ab65-8c3d-4524-ebc7-09761e29b5c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.load_weights(root_path + 'best_adam.h5')\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "706/706 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3917372247293887, 0.8937677053824362]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZtpoS15pr2s",
        "colab_type": "text"
      },
      "source": [
        "### 10.進行預測資料的預測\n",
        "***\n",
        "- 進行預測\n",
        "- 將預測結果儲存csv檔"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iKhmh7lZTgT",
        "colab_type": "code",
        "outputId": "f6672a72-ce03-4550-82e2-bab25ca5a63d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pre = model.predict_classes(xpredict)\n",
        "print(pre.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW_9cmBag799",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = 'drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/image_data/test/'\n",
        "files_name = os.listdir(path)\n",
        "id = list()\n",
        "for i in range(len(files_name)):\n",
        "    name = os.path.splitext(files_name[i])[0]\n",
        "    id.append(name)\n",
        "\n",
        "df = {'id':id, 'flower_class':pre}\n",
        "pred_result = pd.DataFrame(df)\n",
        "pred_result.to_csv('drive/My Drive/ML100_Colab Notebooks/11.ML100_Final test/my_pred_VGG.csv', index=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
